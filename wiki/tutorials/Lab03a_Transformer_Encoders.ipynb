{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Encoders\n",
    "\n",
    "In this tutorial you will explore the **word-piece tokenization**,the **self-attention mechanism**, and how **BERT encoder** put it all together. \n",
    "\n",
    "## Install the libraries\n",
    "If you haven't done so yet, you you need to install the following libraries:\n",
    "\n",
    "    pip install transformers\n",
    "    pip install ipywidgets\n",
    "    pip install bertviz\n",
    "\n",
    "Also, you have to download the following elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vcQwjqCo1ziM",
    "outputId": "eb2b6177-d4e1-4e9d-aa63-0b56a9248c0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FYI: bertviz_repo directory already exists, to pull latest version uncomment this line: !rm -r bertviz_repo\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!test -d bertviz_repo && echo \"FYI: bertviz_repo directory already exists, to pull latest version uncomment this line: !rm -r bertviz_repo\"\n",
    "# !rm -r bertviz_repo # Uncomment if you need a clean pull from repo\n",
    "!test -d bertviz_repo || git clone https://github.com/jessevig/bertviz bertviz_repo\n",
    "if not 'bertviz_repo' in sys.path:\n",
    "  sys.path += ['bertviz_repo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "juNXbazl16D5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pprint\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModel\n",
    "from bertviz import model_view, head_view\n",
    "\n",
    "# Get the interactive Tools for Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fOQQ6zwO19Bg"
   },
   "outputs": [],
   "source": [
    "def call_html():\n",
    "  import IPython\n",
    "  display(IPython.core.display.HTML('''\n",
    "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
    "        <script>\n",
    "          requirejs.config({\n",
    "            paths: {\n",
    "              base: '/static/base',\n",
    "              \"d3\": \"https://cdnjs.cloudflare.com/ajax/libs/d3/5.7.0/d3.min\",\n",
    "              jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
    "            },\n",
    "          });\n",
    "        </script>\n",
    "        '''))\n",
    "    \n",
    "def display_scatterplot(model, words):\n",
    "\n",
    "    if model.shape[1] == 2:\n",
    "        twodim = model\n",
    "    else:\n",
    "        twodim = PCA().fit_transform(model)[:,:2]\n",
    "    \n",
    "    plt.style.use('ggplot')\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(twodim[:,0], twodim[:,1], edgecolors='k', c='r')\n",
    "    for word, (x,y) in zip(words, twodim):\n",
    "        plt.text(x+0.05, y+0.05, word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embedding_dim = 4\n",
    "x = [\n",
    "  [1, 0, 1, 0], # Input 1\n",
    "  [0, 2, 0, 2], # Input 2\n",
    "  [1, 1, 1, 1], # Input 3\n",
    "  [2, 0, 0, 1], # Input 4\n",
    "  [0, 2, 0, 1], # Input 5\n",
    "  [0, 0, 2, 1], # Input 6\n",
    "  [2, 0, 1, 0], # Input 7\n",
    "  [1, 2, 1, 0]  # Input 8\n",
    " ]\n",
    "\n",
    "x = torch.tensor(x, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries, keys and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_embedding_dim = 2\n",
    "\n",
    "w_key = torch.rand(layer_embedding_dim, input_embedding_dim, dtype=torch.float32)\n",
    "w_query = torch.rand(layer_embedding_dim, input_embedding_dim, dtype=torch.float32)\n",
    "w_value = torch.rand(layer_embedding_dim, input_embedding_dim, dtype=torch.float32)\n",
    "\n",
    "keys = torch.matmul(x, w_key.T)\n",
    "querys = torch.matmul(x, w_query.T)\n",
    "values = torch.matmul(x, w_value.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaled Dot Product Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_scores = torch.matmul(querys, keys.T)\n",
    "attn_scores_softmax = softmax(attn_scores, dim=-1)\n",
    "outputs = torch.matmul(attn_scores_softmax, values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Attention Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAGkCAYAAAAIduO+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAo8UlEQVR4nO3de3SU9b3v8c8kmcszMwS5qjRcAgKiRyxK7cFTi1fYu3C20rq1gHvJ7maBwrZ0t6k3SjdYlB1q6abaWq+lbkWbBrycLk+b4lbq7cCxxxYr1srFgwURKCRk7k8yc/4YkjKFSCY+3zNM+n6t5frxzHrm+/s6+T3zyW8myfhyuVxOAAAYqSh1AwCA3o2gAQCYImgAAKYIGgCAKYIGAGCKoAEAmCJoAACmCBoAgCmCBgBgiqABAJiqKnUDXvnFL36hZ599Vs3NzaqpqdGcOXM0bty4Urf1kbZu3apnn31WO3fu1KFDh1RXV6cLLrig1G2d0FNPPaXNmzdr9+7dCgQCGjNmjK677joNGTKk1K2dUFNTk5qamrR//35JUk1Nja6++mpNmDChxJ0V56mnntITTzyhz33uc5ozZ06p2/lIDQ0NamxsLLitb9++evDBB0vUUfcdPHhQjz32mH7zm98ok8no9NNP14033qiRI0eWurWPtHDhws41frQpU6Zo7ty5/9/76RVB8+qrr2rNmjWaO3euxo4dqw0bNuiuu+7Sd7/7XQ0cOLDU7XUpnU5rxIgRuuSSS/Sd73yn1O1029atWzV16lSNGjVK7e3tevLJJ7V8+XKtWrVKoVCo1O19pP79+2vWrFk67bTTJEkbN27UypUrtXLlSg0dOrTE3XXPtm3btGHDBg0fPrzUrXTb0KFDtWTJks7jioqT/8WUWCymJUuW6Oyzz9btt9+u6upqffjhhwqHw6Vu7YRWrFihbDbbebxr1y4tX75ckyZNKkk/vSJofvazn+nSSy/VZZddJkmaM2eOfvvb36qpqUmzZs0qcXddmzBhQtl9Jy1JixcvLjhesGCB5s6dqx07duiss84qUVfdM3HixILjmTNnqqmpSe+++25ZBE0qldI999yj+fPna/369aVup9sqKip0yimnlLqNojzzzDMaMGCAFixY0Hnb4MGDS9hR91VXVxccP/300zr11FNLdn2WfdC0tbVpx44duuqqqwpuHz9+vN55553SNPVXJpFISJKi0WiJOylONpvVa6+9pnQ6rTFjxpS6nW556KGHNGHCBI0fP76sgmbv3r2aP3++qqqqNHr0aM2cOVOnnnpqqdv6SK+//rrOPfdcrVq1Slu3blX//v01ZcoUXX755aVurShtbW166aWXNG3aNPl8vpL0UPZBc/jwYWWzWfXt27fg9r59+6q5ubk0Tf0VyeVy+vGPf6wzzzxTw4YNK3U73bJr1y4tXrxYrusqFAqprq5ONTU1pW7rhF555RXt3LlTK1asKHUrRRk9erQWLlyoIUOGqLm5WevXr9c3vvENrVq1Sn369Cl1e13at2+ffvnLX2ratGmaMWOGtm3bph/96Efy+/2aPHlyqdvrts2bNysej+viiy8uWQ9lHzQdjpfUpUrvvyYPP/ywdu3apTvuuKPUrXTbkCFD9O1vf1vxeFybNm3S97//fS1btuykDpsDBw5ozZo1Wrx4sQKBQKnbKcrRLw8PGzZMY8aM0U033aSNGzdq+vTpJezso2WzWY0aNarz5ffa2lq9//77ampqKqugeeGFF/TJT35S/fv3L1kPZR801dXVqqioOGb30tLScswuB9565JFH9Otf/1rLli3TgAEDSt1Ot1VVVXX+MMCoUaO0fft2Pffcc5o3b16JO+vajh071NLSoltvvbXztmw2q7fffls///nPtXbt2rJ4g12SQqGQhg0bpg8++KDUrXykfv36HfPNR01NjTZt2lSijoq3f/9+bdmyRXV1dSXto+yDpqqqSiNHjtSWLVsKfjR4y5Yt+tSnPlXCznqvXC6nRx55RJs3b9bSpUvL5g3SruRyObmuW+o2PtI555yju+++u+C2++67T0OGDNGVV15ZNiEjSa7ravfu3Sf9rx+MHTtWe/bsKbhtz549GjRoUIk6Kt4LL7ygvn376rzzzitpH2UfNJI0ffp03XPPPRo5cqTGjBmjDRs26MCBA7riiitK3dpHSqVS2rt3b+fxvn379N577ykajZ7UP5b98MMP6+WXX9bNN98sx3E6d5PhcPikf1ln7dq1mjBhggYMGKBUKqVXXnlFb7311jE/SXeycRznmPfAgsGg+vTpc9K/N/boo49q4sSJGjhwoFpaWrRu3Tolk8mT/uWnadOmacmSJVq/fr0uvPBCbdu2Tc8///xJvfM9Wjab1YsvvqjJkyersrKypL30iqC58MIL1draqnXr1unQoUMaOnSobrvttpP+O4/t27dr2bJlncePPvqoJGny5MlauHBhqdo6oaamJknS0qVLC25fsGBBSd9w7I6Wlhbde++9OnTokMLhsIYPH67Fixdr/PjxpW6t1zp48KBWr16tw4cPq7q6WqNHj9add9550l+fZ5xxhurq6rR27VqtW7dOgwcP1vXXX6+LLrqo1K11y5tvvqkDBw7okksuKXUr8uVyuVypmwAA9F7l88IuAKAsETQAAFMEDQDAFEEDADBF0AAATBE0AABTvSpoXNdVQ0PDSf9b3n+pXPuWyrf3cu1bKt/ey7VvqXx7P1n67nVB09jYWPIHtVjl2rdUvr2Xa99S+fZern1L5dv7ydJ3rwoaAMDJh6ABAJjqVUHj8/lUW1tbdp9DU659S+Xbe7n2LZVv7+Xat1S+vZ8sffO3zgAApkr215v/7aZH9cft+zytGXL8unvdItV9YbVSSe/f/HKH2XxCXSjk1+p//wct+sp/KJWyedPuT2cFTeo6gSr9xw3X6h9++BMlM22e1x920S7Pa0pSsDKgFeO/ptu2fEfp9ozJHJlv2jzmoXBAd//kn1V37b1KJbzvPddy2POakhQKB/Wdn9+mr/3NCqUSaZM53rtppEndcJVfP50xU3//1BNKtHl/jQYP2PwZfydQpcf/6VrNftjm+hw5sJ/u/vvPnfC8kgXNH7fv0/bf/dHTmuFo/sLe+fYeJWLeL+R02iYEwuH8Z7hs375PCYMnDkn68JSQSd1IMN/7Ox8cUDztfe9t8fc9rylJTmX+8XgvvlvJ9pTJHOm3HJO61us8+6dDnteUpHCf/GO+43fvK9Fq85i/cyBqUjfqz6/zt/+0XzHX+3Ue+sAmaDquz9/vtbk+u6tXvUcDADj5EDQAAFMEDQDAFEEDADBF0AAATBE0AABTBA0AwBRBAwAwRdAAAEwRNAAAUwQNAMAUQQMAMEXQAABMETQAAFMEDQDAFEEDADDVow8++8UvfqFnn31Wzc3Nqqmp0Zw5czRu3DivewMA9AJF72heffVVrVmzRp///OdVX1+vcePG6a677tKBAwcs+gMAlLmig+ZnP/uZLr30Ul122WWdu5mBAweqqanJoj8AQJkr6qWztrY27dixQ1dddVXB7ePHj9c777xz3Pu4rivXdTuPfT6fHMdRyPF3fva5V5xIsGD0WmU4YFLXcQIFo4WOzw73vq6/YPSaUxkyqhssGC1Uery+O1iv82zG6DGPhgpGC1G/0To/UjdiVD8YrDSpGwn4C0avOYHuRYgvl8vlulv04MGDuuGGG/Stb31LY8eO7bx9/fr12rhxo1avXn3MfRoaGtTY2Nh5XFtbq/r6+u5OCQAocz36YQCfz9et2yRpxowZmj59+jHn1X1htXa+vacn03fJiQT12P++Q9d96ptKxtOe1pak9KjBnteU8juZnzbcpL+/5h4lkxmTOfadZ/NdZCTo1wu3z9Mldz2geNo98R2KNOpvtnteU8rvZB65YIW+tPk2Jdu9XyuSlJlvtDOIBPXYa/+q6yYtM1nn2YPNnteU8juZtb9fpVlnflXJWMpkjneXnmlSN+IPaNP1N+jTP/6h4q7312jwQ7sdza++Pk+f/fYDime8vz7PPG2gHv+na094XlFBU11drYqKCjU3Nxfc3tLSor59+x73Pn6/X37/sdu2VNJVImZzgSfjaZPa6YRNCHRIJjNKGM0RT9v+JHs87Sqe9r73ZLvNE9Kf66fN5kjHjv/Nl1es1nm21fgxj6WUMJojZhACR4u7GZM52tI2QdMhnjG6PjNt3TqvqGefqqoqjRw5Ulu2bCm4fcuWLQUvpQEA0KHol86mT5+ue+65RyNHjtSYMWO0YcMGHThwQFdccYVFfwCAMld00Fx44YVqbW3VunXrdOjQIQ0dOlS33XabBg0aZNEfAKDM9eiHAaZOnaqpU6d63QsAoBfib50BAEwRNAAAUwQNAMAUQQMAMEXQAABMETQAAFMEDQDAFEEDADBF0AAATBE0AABTBA0AwBRBAwAwRdAAAEwRNAAAUwQNAMAUQQMAMNWjDz7zRC6X/8/rmla1JbXWBD2vKUnZUECSFBsSVDzlM5mj3W9StrNuu19qz3pf/42ttd4XlRT1B6RJ0pbfD1fMzZjMMXZA3KRueyS/Dtv791F7MOB5/YrmFs9rSpKvsqJz7Pi318K7Kk3qOsF8XeePlcqmvZ8jPtL1vKYkVfrzzyepT7hKut7PkR7Q1q3z2NEAAEwRNAAAUwQNAMAUQQMAMEXQAABMETQAAFMEDQDAFEEDADBF0AAATBE0AABTBA0AwBRBAwAwRdAAAEwRNAAAUwQNAMAUQQMAMEXQAABMETQAAFMEDQDAVFWxd9i6daueffZZ7dy5U4cOHVJdXZ0uuOACi94AAL1A0TuadDqtESNG6Etf+pJFPwCAXqboHc2ECRM0YcIEi14AAL1Q0UFTLNd15bpu57HP55PjOAqFAwpHg57O5USCBaPXIqGASd1wyF8wWsgGfSZ1IwF/wei1Sr/N24gRf6BgtBCOtJnUdcKBgtFrFX1CJnWdaKhgtBAJ2jwmkaC/YPSaz290fRqvc6eqexHiy+VyuZ5Ocs0115zwPZqGhgY1NjZ2HtfW1qq+vr6nUwIAyoz5jmbGjBmaPn1657HPl0/uui+s1s6tuz2dy4kE9djr39J1E5coGU97WluS/vTZYZ7XlPI7medWz9fnFt2vRMo98R16oHWo3Y7mVzfP02dXPqB4xvveU5+w2RVE/AFtvu5GXfDYfYq7GZM5Rv84YVLXCQf0xHNf08zPfUfJhPe9V+z09rrs4ERDevytuzX77DolYymTOd7/x3EmdSNBv168bZ4uXvGA4mnv13lihM11H/EHtHn2Al3w+A9M1vm4/oPU+HezT3ieedD4/X75/cduN1OJjBIx78NAkpLxtEnteMrmCalDIuWazRFP2wRNZ/2Mq3ja+96Trk3QdIi7GcWMgiZh8M3O0ZKJjMkcFa02IdAhGUspYTSHxRosrG+zzuOuTdD8ub7NOk+2de/65PdoAACmit7RpFIp7d27t/N43759eu+99xSNRjVw4EBPmwMAlL+ig2b79u1atmxZ5/Gjjz4qSZo8ebIWLlzoXWcAgF6h6KA5++yz1dDQYNELAKAX4j0aAIApggYAYIqgAQCYImgAAKYIGgCAKYIGAGCKoAEAmCJoAACmCBoAgCmCBgBgiqABAJgiaAAApggaAIApggYAYIqgAQCYImgAAKaK/uAzr+QOtyp7qNnTmtm2UH5sblG2NeVpbUk65V2bj6oOh11JUt/tcfkTGZM5EqdHTepWHvlWpdLN/+e1mz6zwfuikgIVYUmLNH/Si8pkEyZzbFg8wqRuRTS/ziv+715VxLxf5+0thz2vKUntWfdI/Va1tyZN5kh8ot2kboU/Xzd5ersSrvdzVLXYPBVXBfJ1qw5XqSqT9bx+ZbCyW+exowEAmCJoAACmCBoAgCmCBgBgiqABAJgiaAAApggaAIApggYAYIqgAQCYImgAAKYIGgCAKYIGAGCKoAEAmCJoAACmCBoAgCmCBgBgiqABAJgiaAAApor6/NCnnnpKmzdv1u7duxUIBDRmzBhdd911GjJkiFV/AIAyV1TQbN26VVOnTtWoUaPU3t6uJ598UsuXL9eqVasUCoWsegQAlLGigmbx4sUFxwsWLNDcuXO1Y8cOnXXWWZ42BgDoHYoKmr+USCQkSdFotMtzXNeV67qdxz6fT47jKBQJKNzH212QEw0VjF7LhgMmdZ0jdR2j+pIUCdrUjgT9BaPXAhVho7pOwWghbLQOnWiwYPRau2vzmDhHrnfH4+v+aFG/0To/UjdiVL8ya/N2eSTgLxi95vi7V9eXy+VyPZkgl8tp5cqVisfjuuOOO7o8r6GhQY2NjZ3HtbW1qq+v78mUAIAy1OOgeeihh/TGG2/ojjvu0IABA7o8r6sdzdemLNeON9/vydRdcqIhrX13tWaNXqRkLOVpbUnKnj3S85pSfifz5LP/oi/+3XeVTGRM5vjgv3W96/w4IkG/Xrh9ni656wHF0+6J71Ck62Zu8LymlN/J3DBmrX74h1nKZJMmc7z4t8NM6jrRoB5/c6Vmn3OzkrG05/XbDzV7XlPK72SefP9+fXHofCVbvb8+JWl7/fkmdSP+gDZ96QZ9+pEfKu56f41Wpu12NK/eMF8X/vB+xTPeX59nDhqkn8y89oTn9eils0ceeUS//vWvtWzZso8MGUny+/3yH2d7lYpnlDBabMlYyqR21igEOiQTGSWM5oinbXuPp12TOTLZhOc1C+snzeZIGHyzc7RkLG0yR3urTfB2SLamlDCaI2YQAkeLuxmTOSoztr9pEs+4imW87zvpdi+8ivq/y+Vyevjhh7Vp0yZ985vf1ODBg3vUHADgr0dRQfPwww/rpZde0qJFi+Q4jpqbm9Xc3KyMQVICAHqHol46a2pqkiQtXbq04PYFCxbo4osv9qonAEAvUlTQNDQ0WPUBAOil+FtnAABTBA0AwBRBAwAwRdAAAEwRNAAAUwQNAMAUQQMAMEXQAABMETQAAFMEDQDAFEEDADBF0AAATBE0AABTBA0AwBRBAwAwRdAAAEwV9cFnXvJFwvL1iXpbMxo6MkblM/hfqzwY97ymJFWm2/LjoYQq42mTOfyHIzZ1Q7n82JqTP5XzvP6VfbZ4XlOSKnz5tTct+jtlczGTOTa4NSZ11db259Ft87y8LxDwvObRdX2BgHyBdpM5+g5vMakbqQpKkqqHHVZlm/fXaGBdP89rSlIk/5SoflulQMr7+tXDu3ceOxoAgCmCBgBgiqABAJgiaAAApggaAIApggYAYIqgAQCYImgAAKYIGgCAKYIGAGCKoAEAmCJoAACmCBoAgCmCBgBgiqABAJgiaAAApggaAIApggYAYIqgAQCYqirm5KamJjU1NWn//v2SpJqaGl199dWaMGGCSXMAgPJXVND0799fs2bN0mmnnSZJ2rhxo1auXKmVK1dq6NChJg0CAMpbUUEzceLEguOZM2eqqalJ7777LkEDADiuooLmaNlsVq+99prS6bTGjBnT5Xmu68p13c5jn88nx3EUcgIKR0M9nf64nGiwYPRcxKauc6SuY1RfkiKhgEndcNBfMHqtwhc1qes7Utfni5q9URnu4+367uAcuW4cj6+fDtmAzSNi3bckRapsrqFwVaBg9FrA6voM+QtGrzmB7tX15XK5XDGFd+3apcWLF8t1XYVCIX35y1/Weeed1+X5DQ0Namxs7Dyura1VfX19MVMCAMpY0UHT1tamAwcOKB6Pa9OmTXr++ee1bNky1dTUHPf8rnY0dVeu0o6tuz9e93/BiQb1+Bt3afaE25WMpT2tLUmqtvnu2okE9fivbtfsz96lZNygb0kfTh5kUjcc9OuXK+britvuVyLtnvgORXr0q6s9rynldzIjP/GGduyeoFwuZjLH1ydNManrREN6/O3vaPa4rykZS3leP5vOeF5Tyvf9xI57NHPkTSZ9S9K+Hw83qRuuCmjDFTfr8l+uVKLN+8cn8MwpnteU8juZ5/59vj73lfuVSHl/fY4eOkgPLr72hOcV/dJZVVVV5w8DjBo1Stu3b9dzzz2nefPmHfd8v98vv//Y7VUqmVHCaLElY2mb2pU2288OyXhaCaOgiadsnjw6JNKuyRxZoxDoeHEol4uZzZFotVnfHZKxlMkc2bTNGuyQ7ztpUjveZtt7oi1jModrfX2mbK7PZKZ74fWxX4zN5XIFOxYAAI5WVNCsXbtWb7/9tvbt26ddu3bpiSee0FtvvaWLLrrIqj8AQJkr6qWzlpYW3XvvvTp06JDC4bCGDx+uxYsXa/z48Vb9AQDKXFFBc+ONN1r1AQDopfhbZwAAUwQNAMAUQQMAMEXQAABMETQAAFMEDQDAFEEDADBF0AAATBE0AABTBA0AwBRBAwAwRdAAAEwRNAAAUwQNAMAUQQMAMEXQAABMFfXBZ54KBuRzQp6W9DnBztHX7mlpSdLeiwd7X1RSJBSQJO27aJDiqYzJHOn+PpO6VcF83XQ/n9Jp7+f4mye/7nlNSYoGAvrtIunz6xYplrF5zEeMT5rUdcP59eKePUJuwvve/b9/3/OaklQRDR0ZI6pQpckc2f/sb1M3GJD+Vspu7Kds2vvHfN9Fruc1JSnqz+8l9l/Yppjb5nn9wQO690TLjgYAYIqgAQCYImgAAKYIGgCAKYIGAGCKoAEAmCJoAACmCBoAgCmCBgBgiqABAJgiaAAApggaAIApggYAYIqgAQCYImgAAKYIGgCAKYIGAGCKoAEAmPpYQfPUU0/pmmuu0Zo1azxqBwDQ2/Q4aLZt26YNGzZo+PDhXvYDAOhlehQ0qVRK99xzj+bPn69IJOJ1TwCAXqSqJ3d66KGHNGHCBI0fP17r16//yHNd15Xrup3HPp9PjuMoFA4oHA32ZPouOZFgwei1SChgUjcc9BeMFiqDPpO6kYC/YPRaIJAzqWvdtySFw+0mdZ1woGD0mj8aMqnrHLneHY+v+6NFguV5jWb9RtenP1Awes2p6l6E+HK5XFFX8iuvvKL169drxYoVCgQCWrp0qUaMGKE5c+Yc9/yGhgY1NjZ2HtfW1qq+vr6YKQEAZayoHc2BAwe0Zs0aLV68WIFA9xJyxowZmj59euexz5dP7rpr79XOt/cUM/0JOZGgHnvtX3XdpGVKxtOe1pakDy8d4nlNKf9dUlP9fE255X4l0u6J79ADqQF2O5qNt8zT5PoHFM9437tbbbejefXG+brwvvtN+pakYf8zaVLXCQfUsH6Rrvn8aiUTGc/r+/+w2/OaUn4n8/iWes0ef4uSMe+vT0nac81ok7rhoF//uWyeLv3XB0yu0dazbNZgxB/Q5pkLdMETP1Dc9X6tjOs/SI3TZ5/wvKKCZseOHWppadGtt97aeVs2m9Xbb7+tn//851q7dq0qKgrf9vH7/fL7j91uphIZJYwWWzKeNqkdT3n/hTpaIu2azZFK2wRNh3jGVTztfe+ZjE3QdIhnXMUyNo95wiAEjpZMZEzm8MdSntc8WjKWVsJoDos1eLRE2madx1yboOkQdzOKGQRNsq2tW+cVFTTnnHOO7r777oLb7rvvPg0ZMkRXXnnlMSEDAEBRQeM4joYNG1ZwWzAYVJ8+fY65HQAAib8MAAAw1qMfbz7a0qVLPWgDANBbsaMBAJgiaAAApggaAIApggYAYIqgAQCYImgAAKYIGgCAKYIGAGCKoAEAmCJoAACmCBoAgCmCBgBgiqABAJgiaAAApggaAIApggYAYOpjf/BZj6UzyiVTnpbMVR4Zk2nPa0tSZF+75zUlKezk64b3t0tJmzlSA0v3pf44QmNaTOoGq4L58YzDamtLm8zh32dUN5Lv3b8/Jn/c+zlyiaTnNSUpV5nLj8mkcgnvr09JSg3MmdStCuTrpgfklMp4P4cvZfM9v6+9orO+zzWYI+3r1mnsaAAApggaAIApggYAYIqgAQCYImgAAKYIGgCAKYIGAGCKoAEAmCJoAACmCBoAgCmCBgBgiqABAJgiaAAApggaAIApggYAYIqgAQCYImgAAKYIGgCAKYIGAGCqqA+Sb2hoUGNjY8Ftffv21YMPPuhpUwCA3qOooJGkoUOHasmSJZ3HFRVsigAAXSs6aCoqKnTKKacYtAIA6I2KDpq9e/dq/vz5qqqq0ujRozVz5kydeuqpXZ7vuq5c1+089vl8chxHISegcDTUs6674ESDBaPXsk7ApG74SN2wUX1JSgWL/lJ3SyTgLxi9VlFl87WMVAUKRgvhiE1dJxIsGL2W6+PtddnBOXK9Ox5f90eLBmy+ntbr3PVnTepG/IGC0Wvhqu49Hr5cLpfrbtE33nhD6XRaQ4YMUXNzs9avX6/du3dr1apV6tOnz3Hv85fv69TW1qq+vr67UwIAylxRQfOXUqmUbrrpJl155ZWaPn36cc/pakdTd+Uq7di6u6dTH5cTDerxN+7S7Am3KxlLe1pbkmIXDPO8ppTfyTz90I26au59SiQzJnMcPNNuR7PxlnmaXP+A4hn3xHcoUsV5LZ7XlPI7mRem1umSX9yteJvNY17zTe/XoJTfyTz+q9s1+7N3KRn3fo7cnr2e15TyO5m1767WrNGLlIylTOZ476vnmNSNBPx6edF8fWb1/Sbr3O1rt6PZ9I836NM/+qHirvfrfNyAQfrpF2ae8LyP9ewTCoU0bNgwffDBB12e4/f75fcfu71KJTNKGC22ZCxtUtsqBI6ubzVHPG2zkDvrZ1zF0973XtFm82TdId6WUdxojoRBCBwtGU+bzJFrtbkuOyRjKSWM5ohlbK/ReMY1mcN1ja9PN6OYQdAk2roXuh/rR8Zc19Xu3bvVr1+/j1MGANCLFbWjefTRRzVx4kQNHDhQLS0tWrdunZLJpCZPnmzVHwCgzBUVNAcPHtTq1at1+PBhVVdXa/To0brzzjs1aNAgq/4AAGWuqKD5yle+YtQGAKC34tf6AQCmCBoAgCmCBgBgiqABAJgiaAAApggaAIApggYAYIqgAQCYImgAAKYIGgCAKYIGAGCKoAEAmCJoAACmCBoAgCmCBgBgiqABAJgq6oPPvJSLJ5RrjXlbU235MRZTrjXlaW1Jiv5uv+c1JSkcCebrbz2ginjaZI7WIaeb1A2Ejowtkuv9Q643Pr3W+6KS5ItKul3/a+JPpZy367DD3/7xQpO6uT75Bz23Z6/JOs8mk57XlKRsVUf9lNkcGhO3qVvl5scz4lJbxvPyfTdGPa8pSZFQpSSp+g+VqkxVel4/WtO9muxoAACmCBoAgCmCBgBgiqABAJgiaAAApggaAIApggYAYIqgAQCYImgAAKYIGgCAKYIGAGCKoAEAmCJoAACmCBoAgCmCBgBgiqABAJgiaAAApggaAICpoj/K+eDBg3rsscf0m9/8RplMRqeffrpuvPFGjRw50qI/AECZKypoYrGYlixZorPPPlu33367qqur9eGHHyocDlv1BwAoc0UFzTPPPKMBAwZowYIFnbcNHjzY86YAAL1HUUHz+uuv69xzz9WqVau0detW9e/fX1OmTNHll1/e5X1c15Xrup3HPp9PjuMoFAko3CfU886Pw4mGCkav+SJBk7rOkbqOUX1JioQCJnXDQX/B6Dlf1KhupHA04PX67mC9zrNFv6DePc6Rx8MxelwkKVpls84jR+pGjOo7ZXp9OsHuLRZfLpfLdbfo7NmzJUnTpk3TpEmTtG3bNq1Zs0bz5s3T5MmTj3ufhoYGNTY2dh7X1taqvr6+u1MCAMpcUd+7ZLNZjRo1SrNmzZKUD433339fTU1NXQbNjBkzNH369M5jn88nSfralOXa8eb7Pe37uJxoSGvfXa1ZoxcpGUt5WluSfKfZvEzoRIJ6/OVvaPZnlisZT5vMsfey00zqhoN+bbhzni5f/IASaffEdyjSy19/yPOakiRfRBWDX1Z232ekXNxkii988gKTutbrPJv0vqaU38k8+f79+uLQ+Uq22syx60dnmdSNVAX08n//F33mf3xX8baM5/WdV2x27tbX55hPDNSaf7n2hOcVFTT9+vVTTU1NwW01NTXatGlTl/fx+/3y+4/dtqXiGSWMFlsyljKp7etjEwIdkvG0EkZBE095f3EcLZF2bebIxbyvWVA/bjaH1fruYLXOs8mk5zWPlmxNKdFqM0fMIASOFm/LmMyRLdPrM5lu69Z5Rf0ezdixY7Vnz56C2/bs2aNBgwYVUwYA8FekqKCZNm2a3n33Xa1fv1579+7Vyy+/rOeff15Tp0616g8AUOaKeunsjDPOUF1dndauXat169Zp8ODBuv7663XRRRdZ9QcAKHNF/yDj+eefr/PPP9+iFwBAL8TfOgMAmCJoAACmCBoAgCmCBgBgiqABAJgiaAAApggaAIApggYAYIqgAQCYImgAAKYIGgCAKYIGAGCKoAEAmCJoAACmCBoAgCmCBgBgqugPPvNKrq1dObfN25pue+fodW1Jajutr+c1JckNB/LjqdVyExmTOTI2rcsfPFK/WsoEva//5T2f8r6opFCFo7tPlW7+4DylskmTOXwBv2ldX8AvX6Dd+wkSCe9rSlIu9+ex499e+0PEpm4gf41qW0TKeP91bf2MzWOeq8o/D8b+a0KxNu+fWxL9Ut06jx0NAMAUQQMAMEXQAABMETQAAFMEDQDAFEEDADBF0AAATBE0AABTBA0AwBRBAwAwRdAAAEwRNAAAUwQNAMAUQQMAMEXQAABMETQAAFMEDQDAFEEDADBF0AAATFUVc/LChQu1f//+Y26fMmWK5s6d61lTAIDeo6igWbFihbLZbOfxrl27tHz5ck2aNMnzxgAAvUNRQVNdXV1w/PTTT+vUU0/VWWed5WlTAIDeo6igOVpbW5teeuklTZs2TT6fr8vzXNeV67qdxz6fT47jKBQJKtzH6en0x+VEQwWj19rDAZO6zpG6jlF9SYoEbWpHAv6C0WuhCm/XSIdgRahgtBDuY1PbfJ23Z0zqOkceD8focZGkaKA813l7VbtJ3UhVoGD0WriyexHiy+VyuZ5M8Oqrr+p73/uefvCDH6h///5dntfQ0KDGxsbO49raWtXX1/dkSgBAGepx0Nx5552qrKzUrbfe+pHndbWj+eqld2jHll09mbpLTjSkJ967VzNH/LOSsZSntSWpfeJYz2tK+Z1Mw/pFuubzq5VM2Hw3+cGFYZO6kYBfG2+dp8n/9oDiGffEdyjSxX/3fzyvKeV3MneO/74Wb1modNb7tSJJO6602Y050ZAef+tuzT67zmadNx/2vKaU38k8+ccH9MWaeUq22jzmu75xgUndSMCvlxfN12dW32+yzttrk57XlPI7mdeuWqRJT69WvM3755ZxpwzWTy6//oTn9eils/3792vLli2qq6s74bl+v19+/7HbzVQ8rUSrzYObjKVMarcbhUCHZCKjhNEc8XSPXyXtXv2Mq3ja+95TWZs10iGdTZnNkWjt+iVlL+TXuUHQGF2XHZKtNtenJMUyttdoPOOazNFuEAJHi7dlFDOYI9He1q3zevR7NC+88IL69u2r8847ryd3BwD8FSk6aLLZrF588UVNnjxZlZWVFj0BAHqRooPmzTff1IEDB3TJJZdY9AMA6GWKfuH+3HPPVUNDg0UvAIBeiL91BgAwRdAAAEwRNAAAUwQNAMAUQQMAMEXQAABMETQAAFMEDQDAFEEDADBF0AAATBE0AABTBA0AwBRBAwAwRdAAAEwRNAAAU7YfJP8Rho4d4nnNUCQoSRo5fphS8bTn9bNjTvO8piSFQvkvw6gzBiuV6t5ncBfrlCEhk7ohf773sacNVMr1vvcaZ4TnNSUpWJFfK59whimd9X6tSJLGGz3mkYAkaeR/qVEqbvD59a0xz2tKR12f5w43uT4lKXzaYJu6VX5J0pmDBynR5npeP9vP6PGozF+f404ZrES799fnqD4DunWeL5fL5TyfHQCAI3rVS2fJZFK33HKLkslkqVspSrn2LZVv7+Xat1S+vZdr31L59n6y9N2rgiaXy2nnzp0qt01aufYtlW/v5dq3VL69l2vfUvn2frL03auCBgBw8iFoAACmelXQ+P1+XX311fL7/aVupSjl2rdUvr2Xa99S+fZern1L5dv7ydI3P3UGADDVq3Y0AICTD0EDADBF0AAATBE0AABTBA0AwBRBAwAwRdAAAEwRNAAAU/8PcAKWVGE3jSkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(attn_scores_softmax.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-trained Transformer encoder models\n",
    "\n",
    "There are many models available at HuggingFace models repository. These are stable models that were made available by researchers and the industry.\n",
    "\n",
    "   https://huggingface.co/models\n",
    "\n",
    "The example below is the most popular Transformer model, BERT, a cross-encoder trained on the Next Sentence Prediction task and Masked Language Model task. \n",
    "\n",
    "   https://github.com/UKPLab/sentence-transformers/blob/master/docs/pretrained-models/ce-msmarco.md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p6E3k5NJuO6W",
    "outputId": "e8d8f962-185e-4c6d-9eae-fc236e5a0d06"
   },
   "outputs": [],
   "source": [
    "model_path = 'cross-encoder/ms-marco-MiniLM-L-12-v2'\n",
    "model_path = 'bert-base-uncased'\n",
    "CLS_token = \"[CLS]\"\n",
    "SEP_token = \"[SEP]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "RYKgsb3IkElT",
    "outputId": "862994e3-7daa-4ddf-d471-b66eaddb6385"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "transformers.logging.set_verbosity_warning()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "config = AutoConfig.from_pretrained(model_path,  output_hidden_states=True, output_attentions=True)  \n",
    "model = AutoModel.from_pretrained(model_path, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Tokenization\n",
    "\n",
    "See here for details: https://huggingface.co/docs/transformers/tokenizer_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and tokenize the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': tensor([[1, 1, 1, 1, 1]]),\n",
      " 'input_ids': tensor([[ 101, 1012,  102, 1012,  102]]),\n",
      " 'token_type_ids': tensor([[0, 0, 0, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "sentence_a = \".\"\n",
    "sentence_b = \".\"\n",
    "#inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt', add_special_tokens=True, max_length = 512, padding=True, truncation = True)\n",
    "inputs = tokenizer(sentence_a, sentence_b, return_tensors='pt', add_special_tokens=True, max_length = 512, padding=True, truncation = True)\n",
    "\n",
    "pprint.pprint(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] show me tasks to fortuneteller. [SEP] tell me about lung cancer. [SEP]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(inputs[\"input_ids\"][0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token to Id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101,\n",
      " 2265,\n",
      " 2033,\n",
      " 8518,\n",
      " 2000,\n",
      " 7280,\n",
      " 23567,\n",
      " 2121,\n",
      " 1012,\n",
      " 102,\n",
      " 2425,\n",
      " 2033,\n",
      " 2055,\n",
      " 11192,\n",
      " 4456,\n",
      " 1012,\n",
      " 102]\n"
     ]
    }
   ],
   "source": [
    "input_ids = inputs['input_ids']\n",
    "input_id_list = input_ids[0].tolist() # Batch index 0\n",
    "pprint.pprint(input_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]',\n",
      " 'show',\n",
      " 'me',\n",
      " 'tasks',\n",
      " 'to',\n",
      " 'fortune',\n",
      " '##tell',\n",
      " '##er',\n",
      " '.',\n",
      " '[SEP]',\n",
      " 'tell',\n",
      " 'me',\n",
      " 'about',\n",
      " 'lung',\n",
      " 'cancer',\n",
      " '.',\n",
      " '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "input_tokens_list = tokenizer.convert_ids_to_tokens(input_id_list)\n",
    "pprint.pprint(input_tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 \t [CLS]\n",
      "2265 \t show\n",
      "2033 \t me\n",
      "8518 \t tasks\n",
      "2000 \t to\n",
      "7280 \t fortune\n",
      "23567 \t ##tell\n",
      "2121 \t ##er\n",
      "1012 \t .\n",
      "102 \t [SEP]\n",
      "2425 \t tell\n",
      "2033 \t me\n",
      "2055 \t about\n",
      "11192 \t lung\n",
      "4456 \t cancer\n",
      "1012 \t .\n",
      "102 \t [SEP]\n"
     ]
    }
   ],
   "source": [
    "res = \"\\n\".join(\"{} \\t {}\".format(x, y) for x, y in zip(input_id_list, input_tokens_list))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model inference output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output', 'hidden_states', 'attentions'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token embeddings (per layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of layers embeddings\n",
    "len(outputs['hidden_states'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 768])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The format is as follow:\n",
    "# outputs['hidden_states'][layer_m][0][token_n]\n",
    "layer_m = 3\n",
    "token_n = 1\n",
    "# Get all the embeddings of one layer:\n",
    "output_embeddings = outputs['hidden_states'][layer_m][0]\n",
    "\n",
    "output_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_throat = 2\n",
    "token_cancer = 3\n",
    "\n",
    "# Get the embedding of one particular token in one particular layer\n",
    "throat_output_embedding = outputs['hidden_states'][layer_m][0][token_throat]\n",
    "throat_output_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextual word embeddings (per layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "def get_word_idx(sent: str, word: str):\n",
    "    return sent.split(\" \").index(word)\n",
    "\n",
    "def get_word_vector(inputs, outputs, idx, layer):\n",
    "    \"\"\"Get a word vector by averaging the embeddings of \n",
    "       all word occurrences of that word in the input\"\"\"\n",
    "\n",
    "    # get all token idxs that belong to the word of interest\n",
    "    token_ids_word = np.where(np.array(inputs.word_ids()) == idx)\n",
    "    print(inputs.word_ids())\n",
    "    word_tokens_output = outputs.hidden_states[layer][0][token_ids_word]\n",
    "    print(token_ids_word)\n",
    "    return word_tokens_output.mean(dim=0)\n",
    "\n",
    "def get_word_vector_from_ab(inputs, outputs, word, layer = '-1', ab = 'A'):\n",
    "    \"\"\"\n",
    "    This method extracts a word embedding from the requested layer \n",
    "    for sentence_a or sentence_b. If the word is divided into tokens, \n",
    "    the word embedding will be the average of the corresponding token \n",
    "    embeddings.\n",
    "\n",
    "    NOTE: If the same word occurs multiple times in the sentence, \n",
    "    this method returns the word embedding of the first occurrence.\n",
    "\n",
    "    Keyword arguments:\n",
    "        inputs -- input passed to the transformer\n",
    "        outputs -- output of the transformer\n",
    "        word -- target word\n",
    "        layer -- layer from where the word embedding vector should \n",
    "        be extracted.\n",
    "        ab -- should be 'A' or 'B' indication if the word embedding is to be extracted \n",
    "        from sentence_a or sentence_b, i.e., query or document.\n",
    "    \"\"\"\n",
    "       \n",
    "    sep_token = np.where(np.array(inputs[\"input_ids\"][0].tolist()) == 102)[0][0]\n",
    "    if ab == 'A':\n",
    "        tokens_a = inputs[\"input_ids\"][0][1:sep_token]\n",
    "        sent = tokenizer.decode(tokens_a.tolist())\n",
    "    else:\n",
    "        tokens_b = inputs[\"input_ids\"][0][sep_token+1:-1]\n",
    "        sent = tokenizer.decode(tokens_b.tolist())\n",
    "\n",
    "    word_ids = get_word_idx(sent, word)\n",
    "\n",
    "    # get all token idxs that belong to the word of interest\n",
    "    token_ids_word = np.where(np.array(inputs.word_ids()) == word_ids)[0]\n",
    "    sep_word = np.where(np.array(inputs.word_ids()) == None)[0][1]\n",
    "\n",
    "    if ab == 'A':\n",
    "        token_pos = token_ids_word < sep_word\n",
    "    else:\n",
    "        token_pos = token_ids_word > sep_word\n",
    "        \n",
    "    token_ids_word = token_ids_word[token_pos]\n",
    "    word_tokens_output = outputs.hidden_states[layer][0][token_ids_word]\n",
    "\n",
    "    # Change this to True for inspection\n",
    "    details = True\n",
    "    if details:\n",
    "        input_id_list = input_ids[0].tolist() # Batch index 0\n",
    "        tokens = tokenizer.convert_ids_to_tokens(input_id_list)\n",
    "        str1 = \" \"\n",
    "\n",
    "        print(\"- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \")\n",
    "        print(\"INPUT SEQUENCE TOKENS: \", str1.join(tokens))\n",
    "        print(\"TARGET WORD:\", word)\n",
    "        print(\"TARGET SENTENCE:\", ab)\n",
    "        print(\"TARGET SENTENCE WORDS [\", sent, \"]\")\n",
    "        print(\"The word [\", word, \"] occurs in position\", idx, \"of the BERT input sentence\", ab)\n",
    "        print(\"The word [\", word, \"] corresponds to the token(s)\", token_ids_word, \"of the BERT input sequence\", ab)\n",
    "\n",
    "    return word_tokens_output.mean(dim=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'treatable' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m sentence_a \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist())\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[CLS] \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m [SEP]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m word \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtreatable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[43mget_word_idx\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput sequence:\u001b[39m\u001b[38;5;124m\"\u001b[39m, sentence_a)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe word \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, word, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m occurs in position\u001b[39m\u001b[38;5;124m\"\u001b[39m, idx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof the BERT input sequence.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[22], line 6\u001b[0m, in \u001b[0;36mget_word_idx\u001b[0;34m(sent, word)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_word_idx\u001b[39m(sent: \u001b[38;5;28mstr\u001b[39m, word: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: 'treatable' is not in list"
     ]
    }
   ],
   "source": [
    "\n",
    "# The code below converts the tokens into a space delimited string.\n",
    "# This will allow computing in which position of the BERT input sequence a given word is.\n",
    "sentence_a = tokenizer.decode(inputs[\"input_ids\"][0].tolist()).replace(\"[CLS] \", '').replace(\" [SEP]\", '')\n",
    "word = \"treatable\"\n",
    "idx = get_word_idx(sentence_a, word)\n",
    "print(\"Input sequence:\", sentence_a)\n",
    "print(\"The word \\\"\", word, \"\\\" occurs in position\", idx, \"of the BERT input sequence.\")\n",
    "\n",
    "word_embedding = get_word_vector(inputs, outputs, idx, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding = get_word_vector_from_ab(inputs, outputs, \"treatable\", 4, 'A')\n",
    "word_embedding.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output layer embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the last layer is the output embedding layer\n",
    "output_embeddings = outputs['last_hidden_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_scatterplot(output_embeddings[0].detach().numpy(), input_tokens_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-attention matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = outputs['attentions']\n",
    "\n",
    "# The format of the attention tensor is:\n",
    "#     attention[layer][sample_n][head][token1][token2]\n",
    "\n",
    "layer = 3      # Transformer layer\n",
    "sample_n = 0   # Input sample\n",
    "head = 3       # Head of the selected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the score of the attention of one token vs the other token\n",
    "attention[layer][sample_n][head][token_throat][token_cancer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention[layer][sample_n][head].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's a softmax, so, the sum should be 1 \n",
    "attention[layer][sample_n][head][token_throat].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention[layer][sample_n][head][token_cancer].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(attention[layer][0][head], cmap='gnuplot')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "model_view_bert_msmarco_aula.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Tutorials (GPU)",
   "language": "python",
   "name": "tutorials"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
