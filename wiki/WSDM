---
title: Web Search and Data Mining
layout: wiki
---

## Course Description

Web Search and Data Mining (WiSDoM) is an area that aims at extracting knowledge from the largest source of information created by humans: The Web! 
Throughout this course we will see how this extracted knowledge can solve complex tasks with advanced Computer Vision, Natural Language and Information Retrieval algorithms. The main topics of this course are:

 - Text and visual data representation
 - Billion scale text and image search
 - Visual question answering
 - Multimodal conversational assistants
 - Recommender systems

This course includes intensive hands-on laboratories where key CV, NLP and IR algorithms are examined. 

## Objectives
 - Learn what is an information embedding.
 - Learn the semantic associations between visual data, natural language data and user data.
 - Learn how to relate user information needs to actionable data.
 - Learn how to do a critical analysis of experimental results.
 - Develop autonomous and creative problem solving skills.

## Grading
 - Exam (40%) 
 - Project (45% = 20% phase 1 + 15% phase 2 + 10% phase 3) 
 - Project originality (15%)

## Schedule
 - 09/mar/21	1	Introduction
 - 16/mar/21	2	Word embeddings
 - 23/mar/21	3	Indexing
 - 30/mar/21	4	Web document categorization
 - 06/abr/21	5	Transformer (encoder)
 - 13/abr/21	6	Visual search
 - 20/abr/21	7	Joint vision-and-language models
 - 27/abr/21		ExpoFCT
 - 04/mai/21	8	Multimodal conversational assistants
 - 11/mai/21	9	Pre-trained models
 - 18/mai/21	10	Summarization (decoder)
 - 25/mai/21	11	Recommender systems
 - 01/jun/21	12	Invited lecture
 - 08/jun/21	13	Project discussion / Test

## Labs
We suggest you to use the account in the lab cluster. However, if you would like to have your own setup, you can follow this guide:
 
 - Lab 0 - [Environment setup instructions](/wiki/lab_setup)
 
For project phase 1, you will use the OpenSearch server to index and search your data:

 - Lab 1 - [OpenSearch](/wiki/tutorials/OpenSearch)
 - Lab 2 - [Dual-encoders](/wiki/tutorials/dual-encoders)

For project phase 2, you will use Visual-Natural Language Transformers to enrich you data:

 - Lab 3 - [Visual Models of Natural Language](/wiki/tutorials/clip)

For project phase 3, you will implement your own Intent detector to leverage your own Dialog Manager:

 - Lab 4 - [Intent detection and slot filling](/wiki/tutorials/intent-detector)

## Lecturers
Joao Magalhaes (jmag@xfct.unlx.pt - remove the 'x' character to send an email)
