{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Tutorial\n",
    "\n",
    "\n",
    "## Install the libraries\n",
    "First you need to install the following libraries:\n",
    "\n",
    "    pip install transformers\n",
    "    pip install ipywidgets\n",
    "    pip install bertviz\n",
    "\n",
    "Once everything is installed you can download "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vcQwjqCo1ziM",
    "outputId": "eb2b6177-d4e1-4e9d-aa63-0b56a9248c0e"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!test -d bertviz_repo && echo \"FYI: bertviz_repo directory already exists, to pull latest version uncomment this line: !rm -r bertviz_repo\"\n",
    "# !rm -r bertviz_repo # Uncomment if you need a clean pull from repo\n",
    "!test -d bertviz_repo || git clone https://github.com/jessevig/bertviz bertviz_repo\n",
    "if not 'bertviz_repo' in sys.path:\n",
    "  sys.path += ['bertviz_repo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "juNXbazl16D5"
   },
   "outputs": [],
   "source": [
    "from bertviz import model_view, head_view\n",
    "from transformers import *\n",
    "\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "# Get the interactive Tools for Matplotlib\n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fOQQ6zwO19Bg"
   },
   "outputs": [],
   "source": [
    "def call_html():\n",
    "  import IPython\n",
    "  display(IPython.core.display.HTML('''\n",
    "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
    "        <script>\n",
    "          requirejs.config({\n",
    "            paths: {\n",
    "              base: '/static/base',\n",
    "              \"d3\": \"https://cdnjs.cloudflare.com/ajax/libs/d3/5.7.0/d3.min\",\n",
    "              jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
    "            },\n",
    "          });\n",
    "        </script>\n",
    "        '''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p6E3k5NJuO6W",
    "outputId": "e8d8f962-185e-4c6d-9eae-fc236e5a0d06"
   },
   "outputs": [],
   "source": [
    "#model_path = 'nboost/pt-bert-base-uncased-msmarco'\n",
    "model_path = 'bert-base-uncased'\n",
    "\n",
    "CLS_token = \"[CLS]\"\n",
    "SEP_token = \"[SEP]\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the required tokenizer, configuration and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "RYKgsb3IkElT",
    "outputId": "862994e3-7daa-4ddf-d471-b66eaddb6385"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "config = AutoConfig.from_pretrained(model_path,  output_hidden_states=True, output_attentions=True)  \n",
    "model = AutoModel.from_pretrained(model_path, config=config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "\n",
    "See here for details: https://huggingface.co/docs/transformers/tokenizer_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_a = \"Is throat cancer treatable nowadays?\"\n",
    "sentence_b = \"Tell me about lung cancer.\"\n",
    "sentence_a = \"58-year-old woman with hypertension\"\n",
    "sentence_b = \"BACKGROUND : Longitudinal studies hypertension\"\n",
    "inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt', add_special_tokens=True, max_length = 512, truncation = True)\n",
    "pprint.pprint(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(inputs[\"input_ids\"][0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = inputs['input_ids']\n",
    "pprint.pprint(input_ids[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_id_list = input_ids[0].tolist() # Batch index 0\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_id_list)\n",
    "pprint.pprint(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model inference output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the last layer is the output embedding layer\n",
    "output_embeddings = outputs['last_hidden_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_throat = 2\n",
    "token_lung = 11\n",
    "# out[0][token]\n",
    "throat_output_embedding = output_embeddings[0][token_throat]\n",
    "throat_output_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states = outputs['hidden_states']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the output token embedding for the word throat\n",
    "# hidden_states[layer][0][token])\n",
    "layer = 0\n",
    "throat_input_embedding = hidden_states[layer][0][token_throat]\n",
    "throat_input_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-attention matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = outputs['attentions']\n",
    "# The format of the attention tensor is:\n",
    "# attention[layer][0][head][token1][token2]\n",
    "layer = 3\n",
    "head = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will given the attention from one token vs the other token\n",
    "attention[layer][0][head][token_throat][token_lung]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's a softmax, so, the sum should be 1 \n",
    "attention[layer][0][head][token_throat].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention[layer][0][head][token_throat].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Word embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_idx(sent: str, word: str):\n",
    "    return sent.split(\" \").index(word)\n",
    "\n",
    "def get_word_vector(inputs, outputs, idx, layer):\n",
    "    \"\"\"Get a word vector by averaging the embeddings of \n",
    "       all word occurrences of that word in the input\"\"\"\n",
    "\n",
    "    # get all token idxs that belong to the word of interest\n",
    "    token_ids_word = np.where(np.array(inputs.word_ids()) == idx)\n",
    "    word_tokens_output = outputs.hidden_states[layer][0][token_ids_word]\n",
    "\n",
    "    return word_tokens_output.mean(dim=0)\n",
    "\n",
    "# The code below converts the tokens into a space delimited string.\n",
    "# This will allow computing in which position of the BERT input sequence a given word is.\n",
    "sentence_a = tokenizer.decode(inputs[\"input_ids\"][0].tolist()).replace(\"[CLS] \", '').replace(\" [SEP]\", '')\n",
    "word = \"hypertension\"\n",
    "idx = get_word_idx(sentence_a, word)\n",
    "print(\"Input sequence:\", sentence_a)\n",
    "print(\"The word \\\"\", word, \"\\\" occurs in position\", idx, \"of the BERT input sequence.\")\n",
    "\n",
    "word_embedding = get_word_vector(inputs, outputs, idx, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "def get_word_vector_from_ab(inputs, outputs, word, layer = '-1', ab = 'A'):\n",
    "    \"\"\"\n",
    "    This method extracts a word embedding from the requested layer \n",
    "    for sentence_a or sentence_b. If the word is divided into tokens, \n",
    "    the word embedding will be the average of the corresponding token \n",
    "    embeddings.\n",
    "\n",
    "    NOTE: If the same word occurs multiple times in the sentence, \n",
    "    this method returns the word embedding of the first occurrence.\n",
    "\n",
    "    Keyword arguments:\n",
    "        inputs -- input passed to the transformer\n",
    "        outputs -- output of the transformer\n",
    "        word -- target word\n",
    "        layer -- layer from where the word embedding vector should \n",
    "        be extracted.\n",
    "        ab -- should be 'A' or 'B' indication if the word embedding is to be extracted \n",
    "        from sentence_a or sentence_b, i.e., query or document.\n",
    "    \"\"\"\n",
    "       \n",
    "    sep_token = np.where(np.array(inputs[\"input_ids\"][0].tolist()) == 102)[0][0]\n",
    "    if ab == 'A':\n",
    "        tokens_a = inputs[\"input_ids\"][0][1:sep_token]\n",
    "        sent = tokenizer.decode(tokens_a.tolist())\n",
    "    else:\n",
    "        tokens_b = inputs[\"input_ids\"][0][sep_token+1:-1]\n",
    "        sent = tokenizer.decode(tokens_b.tolist())\n",
    "\n",
    "    word_ids = get_word_idx(sent, word)\n",
    "\n",
    "    # get all token idxs that belong to the word of interest\n",
    "    token_ids_word = np.where(np.array(inputs.word_ids()) == word_ids)[0]\n",
    "    sep_word = np.where(np.array(inputs.word_ids()) == None)[0][1]\n",
    "\n",
    "    if ab == 'A':\n",
    "        token_pos = token_ids_word < sep_word\n",
    "    else:\n",
    "        token_pos = token_ids_word > sep_word\n",
    "        \n",
    "    token_ids_word = token_ids_word[token_pos]\n",
    "    word_tokens_output = outputs.hidden_states[layer][0][token_ids_word]\n",
    "\n",
    "    # Change this to True for inspection\n",
    "    details = True\n",
    "    if details:\n",
    "        input_id_list = input_ids[0].tolist() # Batch index 0\n",
    "        tokens = tokenizer.convert_ids_to_tokens(input_id_list)\n",
    "        str1 = \" \"\n",
    "\n",
    "        print(\"- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \")\n",
    "        print(\"INPUT SEQUENCE TOKENS: \", str1.join(tokens))\n",
    "        print(\"TARGET WORD:\", word)\n",
    "        print(\"TARGET SENTENCE:\", ab)\n",
    "        print(\"TARGET SENTENCE WORDS [\", sent, \"]\")\n",
    "        print(\"The word [\", word, \"] occurs in position\", idx, \"of the BERT input sentence\", ab)\n",
    "        print(\"The word [\", word, \"] corresponds to the token(s)\", token_ids_word, \"of the BERT input sequence\", ab)\n",
    "\n",
    "    return word_tokens_output.mean(dim=0)\n",
    "\n",
    "\n",
    "word_embedding = get_word_vector_from_ab(inputs, outputs, \"woman\", 4, 'A')\n",
    "\n",
    "word_embedding = get_word_vector_from_ab(inputs, outputs, \"hypertension\", 4, 'B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention visualization\n",
    "\n",
    "More details are available here: https://github.com/jessevig/bertviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_html()\n",
    "head_view(attention, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_view(attention, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other pre-trained BERT models\n",
    "\n",
    "There are many other models available for download (https://huggingface.co/models).\n",
    "\n",
    "BioBERT is a popular BERT model trained on biomedical literature (https://academic.oup.com/bioinformatics/article/36/4/1234/5566506):\n",
    "\n",
    "    model_path = 'dmis-lab/biobert-v1.1'\n",
    "\n",
    "Another popular BERT is the SciBERT trained on scientific literature (https://arxiv.org/abs/1903.10676):\n",
    "\n",
    "    model_path = 'allenai/scibert_scivocab_uncased'\n",
    "\n",
    "See above where the variable 'model_path' is defined."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "model_view_bert_msmarco_aula.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ri2022",
   "language": "python",
   "name": "ri2022"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
