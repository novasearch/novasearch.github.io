{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reranking with BERT \n",
    "\n",
    "\n",
    "## Install the libraries\n",
    "First you need to install the following libraries:\n",
    "\n",
    "    pip install transformers\n",
    "    pip install ipywidgets\n",
    "    pip install bertviz\n",
    "\n",
    "Once everything is installed you can download "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vcQwjqCo1ziM",
    "outputId": "eb2b6177-d4e1-4e9d-aa63-0b56a9248c0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FYI: bertviz_repo directory already exists, to pull latest version uncomment this line: !rm -r bertviz_repo\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!test -d bertviz_repo && echo \"FYI: bertviz_repo directory already exists, to pull latest version uncomment this line: !rm -r bertviz_repo\"\n",
    "# !rm -r bertviz_repo # Uncomment if you need a clean pull from repo\n",
    "!test -d bertviz_repo || git clone https://github.com/jessevig/bertviz bertviz_repo\n",
    "if not 'bertviz_repo' in sys.path:\n",
    "  sys.path += ['bertviz_repo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "juNXbazl16D5"
   },
   "outputs": [],
   "source": [
    "from bertviz import model_view, head_view\n",
    "from transformers import *\n",
    "\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "# Get the interactive Tools for Matplotlib\n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p6E3k5NJuO6W",
    "outputId": "e8d8f962-185e-4c6d-9eae-fc236e5a0d06"
   },
   "outputs": [],
   "source": [
    "#model_path = 'nboost/pt-bert-base-uncased-msmarco'\n",
    "model_path = 'bert-base-uncased'\n",
    "\n",
    "CLS_token = \"[CLS]\"\n",
    "SEP_token = \"[SEP]\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the required tokenizer, configuration and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "RYKgsb3IkElT",
    "outputId": "862994e3-7daa-4ddf-d471-b66eaddb6385"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "config = AutoConfig.from_pretrained('bert-base-uncased',  output_hidden_states=True, output_attentions=True)  \n",
    "model = AutoModel.from_pretrained('bert-base-uncased', config=config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural ranking\n",
    "\n",
    "The next sentence prediction task is closely related to the ranking task, where the first sentence is the query and the second sentence is the relevant document.\n",
    "\n",
    "The next sentence prediction task uses the \\[CLS\\] output embedding to make the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is covid 19 ?\"\n",
    "document = \"Covid 19 is an infectious disease caused by the SARS-CoV-2 virus.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  2054,  2003,  2522, 17258,  2539,  1029,   102,  2522, 17258,\n",
      "          2539,  2003,  2019, 16514,  4295,  3303,  2011,  1996, 18906,  2015,\n",
      "          1011,  2522,  2615,  1011,  1016,  7865,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "# Generate the input sequence \n",
    "inputs_qa = tokenizer.encode_plus(query, document, return_tensors='pt', add_special_tokens=True, max_length = 512, truncation = True)\n",
    "print(inputs_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] what is covid 19? [SEP] covid 19 is an infectious disease caused by the sars - cov - 2 virus. [SEP]\n"
     ]
    }
   ],
   "source": [
    "# Check the generated input sequence\n",
    "decoded_input_qa = tokenizer.decode(inputs_qa[\"input_ids\"][0])\n",
    "print(decoded_input_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_qa = model(**inputs_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "# The CLS embedding on the last layer is designed to feed a sigmoid function (logistic regression)\n",
    "cls_embedding = outputs_qa[\"last_hidden_state\"][0,0]\n",
    "print(cls_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The CLS embedding of a (q,d) pair replaces the many individual retrieval models\n",
    "# However, its values are not interpretable like the doc scores of classic retrieval models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "model_view_bert_msmarco_aula.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "NLP & IR",
   "language": "python",
   "name": "nlp-ir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
